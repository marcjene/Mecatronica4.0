{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesión 5. Ejemplo de aprendizaje supervisado: regresión.\n",
    "\n",
    "## Predicción de generación fotovoltaica para autoconsumo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Predecir la generación FV del día siguiente de un hogar, para gestionar de forma inteligente su consumo. Utilizaremos datos históricos de la variable objetivo que queremos predecir (datos históricos de generación fotovoltaica) y otras características que pueden ayudar a predecir el modelo, como la irradiancia o la temperatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de empezar:\n",
    "\n",
    "* En el archivo **S5_examplePV1.csv** está el conjunto de datos de entrada para este ejemplo (atributos + etiqueta). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importar librerías y datos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#importamos dataset\n",
    "dataset = pd.read_csv('Data/S5_ejemploPV1.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Entender los datos**\n",
    "\n",
    "Es necesario visualizar y entender los datos con los que vamos a trabajar, así como conocer sus características. \n",
    "\n",
    "1. ¿Cuántas filas tenemos? Cuántos atributos hay en los datos?  \n",
    "2. Cuáles son esos atributos?\n",
    "3. ¿Faltan datos?\n",
    "4. Resumen estadístico del conjunto de datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántos atributos hay en los datos?**Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué significan?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# primeras cinco filas\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data format\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir localhour en datetime\n",
    "dataset['localhour'] = pd.to_datetime(dataset['localhour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Falta algún dato? Se comprueba si falta algún dato y, en caso afirmativo, se realiza el recuento de celdas vacías en cada atributo. En este caso, no falta ningún dato.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Resumen estadístico de los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "##pandas profiling\n",
    "#apply ProfileReport\n",
    "profile = ProfileReport(dataset, title='Profile Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile.to_file(\"your_report2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar los datos.\n",
    "\n",
    "Una forma visual de entender los datos de entrada. \n",
    "\n",
    "1. Boxplots y gráficos de densidad\n",
    "2. Matriz de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Boxplots\n",
    "\n",
    "El diagrama boxplot nos permite identificar valores atípicos y comparar distribuciones. Además, sabemos cómo se distribuye el 50% de los valores (dentro de la caja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset.plot(kind='box', subplots=True, layout=(3, 3), figsize=(15, 10), sharex=False,\n",
    "                                 sharey=False, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Añadir otros gráficos que conozcas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matriz de correlación** \n",
    "\n",
    "**3.2. Cuadro de atributos de doble entrada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seaborn visualization library\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculation of correlation coefficients\n",
    "corr = dataset.corr(method='pearson') \n",
    "# Remove repeated values\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "#Generar Heat Map,\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\" , mask=mask,)\n",
    "    # xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    # yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    # plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Preparar los datos*.\n",
    "\n",
    "1. Limpieza de datos\n",
    "2. Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Limpieza de datos**\n",
    "\n",
    "No hay Nan en los datos de entrada y no se eliminarán valores atípicos en este ejemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Transformación**. \n",
    "\n",
    "Añado las columnas ``time`` y ``month`` a través de la columna datetime. \n",
    "Los datos se escalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and time columns\n",
    "#dataset['month'] = pd.DatetimeIndex(dataset['localhour']).month\n",
    "#dataset['hour'] = pd.DatetimeIndex(dataset['localhour']).hour\n",
    "#dataset.drop(['localhour'], axis=1, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divido los datos en **atributos**: X (características) y **etiquetas**: y (objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features X ; Target y \n",
    "# X = dataset.drop(['pvgen'], axis=1) \n",
    "# y = dataset['pvgen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se escalan utilizando el método ``MinMaxScaler()``, que escala y traduce cada atributo individualmente de forma que esté dentro del rango [0, 1]. Esto debe hacerse cuando las escalas de los atributos son diferentes (por ejemplo, radiación [0, 650], velocidad del viento [2, 15])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# I scale attributes/features\n",
    "scaler = MinMaxScaler()\n",
    "X_df = X.copy()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_df))\n",
    "X_scaled.columns = X_df.columns\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## new scaler instance\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# I scale the target/label\n",
    "y_df = y.copy()\n",
    "y_df = pd.DataFrame(y_df)\n",
    "y_scaled = scaler_y.fit_transform(y_df)\n",
    "# y_scaled.columns = y_df.columns\n",
    "y_scaled = np.ravel(y_scaled)\n",
    "y_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5. Dividir los datos*.\n",
    "\n",
    "Los datos se dividen en datos de entrenamiento ``X_train``, ``y_train``, datos de validación ``X_val``, ``y_val`` y datos de prueba ``X_test``, ``y_test``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size =   # percentage of the input data that I will use to validate the model\n",
    "\n",
    "# I divide the data into training, validation and test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train=train_size,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=train_size,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6. Construcción y evaluación de modelos*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las métricas de evaluación seleccionadas son **RMSE y R2**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "num_folds = 5\n",
    "error_metrics = {'neg_root_mean_squared_error', 'r2'}\n",
    "models = {('MLP', MLPRegressor()),('RFR', RandomForestRegressor()),\n",
    "          ('SVR', SVR()), ('AdaB', AdaBoostRegressor())}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib==3.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the models is trained, the results are saved and compared visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Cross-validation training\n",
    "for scoring in error_metrics:\n",
    "    results = [] # store metrics results\n",
    "    msg = []  # print summary of result\n",
    "    names = []  # store name of the models\n",
    "    print('Evaluation metric: ', scoring)\n",
    "    for name, model in models:\n",
    "        print('Model ', name)\n",
    "        cross_validation = KFold(n_splits=num_folds, shuffle=False)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cross_validation, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        resume = (name, cv_results.mean(), cv_results.std())\n",
    "        msg.append(resume)\n",
    "    print(msg)\n",
    "\n",
    "    # Compare results between algorithms\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Compare metric result for algorithms: %s' %scoring)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('Candidate models')\n",
    "    ax.set_ylabel('%s' %scoring)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7. Ajuste de los hiperparámetros*.\n",
    "\n",
    "Pasos para realizar el ajuste de los hiperparámetros:\n",
    "*Especificar el modelo a ajustar\n",
    "* Especificar una métrica a optimizar\n",
    "* Definir los rangos de los parámetros de búsqueda: *parámetros*\n",
    "* Asignar un método de validación: *KFold*\n",
    "* Buscar los hiperparámetros con los datos de validación: *X_val*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestRegressor()\n",
    "scoring='r2'\n",
    "params = {\n",
    "    # Number of trees in random forest\n",
    "    'n_estimators': [100, 500, 800, 1000],  # default=100\n",
    "     # Maximum number of levels in tree\n",
    "    'max_depth': [2, None],  #deafult = None\n",
    "     # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "\n",
    "# Search for the best combination of hyperparameters\n",
    "cross_validation = KFold(n_splits=5, shuffle=False)\n",
    "my_cv = cross_validation.split(X_val)\n",
    "gsearch = GridSearchCV(estimator=modelo, param_grid=params, scoring=scoring, cv=my_cv)\n",
    "gsearch.fit(X_val, y_val)\n",
    "\n",
    "# Print best Result\n",
    "print(\"Best result: %f using the following hyperparameters %s\" % (gsearch.best_score_, gsearch.best_params_))\n",
    "means = gsearch.cv_results_['mean_test_score']\n",
    "stds = gsearch.cv_results_['std_test_score']\n",
    "params = gsearch.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *8. Evaluación final del modelo*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se realizan predicciones de generación fotovoltaica.\n",
    "\n",
    "Métricas de evaluación:\n",
    "  * RMSE\n",
    "  * R2\n",
    "\n",
    "    \n",
    "El modelo ``fit()`` se entrena con los hiperparámetros óptimos encontrados en el apartado anterior y a continuación se realizan las predicciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestRegressor(n_estimators=800) ## train again with the winner model from the Grid Search\n",
    "final_model.fit(X_train,y_train)  # Model training \n",
    "y_predict = final_model.predict(X_test)  # prediction calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario invertir el escalado ``MinmaxScaler()`` para evaluar nuestros resultados en la dimensión original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# Invert the scaling and plot the results\n",
    "y_test_unsc = np.reshape(y_test, (len(y_test), 1))\n",
    "y_test_inv = scaler_y.inverse_transform(y_test_unsc)\n",
    "\n",
    "y_predict_uns = np.reshape(y_predict, (len(y_predict), 1))\n",
    "y_predict_inv = scaler_y.inverse_transform(y_predict_uns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error RMSE de test  \n",
    "math.sqrt(mean_squared_error(y_test_inv, y_predict_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados gráficos obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_predict vs y_test\n",
    "\n",
    "x = range(len(y_predict_inv))\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.xlabel('Time', size=15)\n",
    "plt.ylabel('Energy produced (kWh)', size=15)\n",
    "plt.plot(x, y_predict_inv, alpha=0.4, color='blue', label='PV predict')\n",
    "plt.plot(x, y_test_inv, alpha=0.4, color='red',  label='PV real')\n",
    "plt.title('Prediction vs Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Necesitamos hacer Zoom!\n",
    "\n",
    "Si es necesario, instale la biblioteca Plotly ``!pip install plotly``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go  # Importamos la librería de plotly\n",
    "\n",
    "init = list(range(len(y_predict_inv)))\n",
    "y_predict_plot = pd.DataFrame(data=y_predict_inv, index=init, columns=['predict'])\n",
    "y_test_plot = pd.DataFrame(data=y_test_inv, index=init, columns=['test'])\n",
    "\n",
    "\n",
    "# We create figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=init, y=y_predict_plot['predict'][init],\n",
    "                    mode='lines',\n",
    "                    name='PV prediction'))\n",
    "fig.add_trace(go.Scatter(x=init, y=y_test_plot['test'][init],\n",
    "                     mode='lines', name='PV real'))\n",
    "\n",
    "\n",
    "# We edit figure\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=1000,\n",
    "                    height=500,\n",
    "                    title='Prediccion vs Real',\n",
    "                   xaxis_title='Periods',\n",
    "                   yaxis_title='Energy (kWh)')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características/atributos más importantes \n",
    "\n",
    "¿Qué características tienen más peso en este ejemplo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print the feature ranking\n",
    "importances = gsearch.best_estimator_.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in gsearch.best_estimator_.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat = X.columns\n",
    "feat_or=[]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]])+feat[indices[f]])\n",
    "    feat_or.append(feat[indices[f]])\n",
    "\n",
    "# We plot the weight of the features that matter most for RandomForest()\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), feat_or)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
