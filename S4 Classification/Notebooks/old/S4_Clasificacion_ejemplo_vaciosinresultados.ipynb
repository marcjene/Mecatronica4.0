{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/top_ML.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 4. Ejemplo de aprendizaje supervisado: clasificación.\n",
    "\n",
    "## *Clasificación binaria de precios de electricidad en el Mercado Diario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** predecir en qué horas el precio de la electricidad en el Mercado Diario será elevado, siendo la **clase 0** para valores menores al cuartil superior Q3, y **clase 1** para valores mayores al cuartil superior Q3 (precio electricidad > Q3 = 59 €/MWh).  Se utilizarán datos históricos de la variable target que queremos clasificar y de otros atributos (features) que pueden ayudar a predecir modelo.\n",
    "\n",
    "\n",
    "**Contexto:** Una empresa que compre energía directamente en el mercado diario, quiere conocer el día anterior en que franjas horarias del dia siguiente el coste de la electricidad va a ser excesivamente elevado. Así pueden re-organizar (si es pobible) el consumo de las cargas o descargar baterías durante esas horas, reduciendo el coste de la factura eléctrica.\n",
    "\n",
    "### Antes de empezar:\n",
    "\n",
    "* En el archivo **S4_ejemplo.csv** se encuentra el conjunto de datos de entrada de este ejemplo (atributos + etiqueta). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importar librerías y datos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el conjunto de datos de entrada\n",
    "dataset = pd.read_csv('Data/S4_ejemplo.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Comprender los datos**\n",
    "\n",
    "Es necesario visualizar y comprender los datos con los que vamos a trabajar, así como conocer sus características. \n",
    "\n",
    "1. ¿Cuántos datos hay? ¿Cuántos atributos hay en los datos?  \n",
    "2. ¿Qué significan?\n",
    "3. ¿Falta algún dato?\n",
    "4. ¿Están balanceadas las etiquetas? \n",
    "4. Resumen estadístico del conjunto de datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cuántos datos hay?**  Hay 21551 filas y 10 columnas en total.  **¿Cuántos atributos hay en los datos?** Existen 9 atrubutos y 1 etiqueta (lo que queremos clasificar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filasxcolumnas de los datos\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observa las primeras 5 filas de datos\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observa las últimas 5 filas de datos\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ¿Qué significan?** \n",
    "* ***[Hora, Mes]*** Hora y mes de cada una de las observaciones. Son valores enteros *int64*.\n",
    "\n",
    "* ***[Hidraul, Eolica, Ciclocomb, Cogener, Nuclear, Carbon]*** se refiere a la energía programada horaria en el mercado diario por tipo de producción.  Son valores reales *float*.\n",
    "\n",
    "* ***[Demanda]*** es la totalidad de energía programada en el mercado diario eléctrico en España.  Son valores reales *float*.\n",
    "\n",
    "* ***[Clases]*** son las etiquetas de precio que queremos predecir. Son valores enteros *int64*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de los datos\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Falta algún dato?** Se comprueba si falta algún dato, y de ser así, se realiza el recuento de celdas vacías en cada atributo. En este caso, no falta ningún dato en el conjunto de datos de entrada (no existen valores *Nan*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si falta algún dato y en qué atributo\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. ¿Están balanceadas las etiquetas?** Existe un desbalance de las etiquetas. La etiqueta 0 abarca un 74% de las muestras, mientras que la 1, un 26%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si las etiquetas están desvalanceadas\n",
    "dataset['Clases'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Resumen estadístico del conjunto de datos de entrada:** La estadística descriptiva recolecta y analiza el conjunto de datos de entrada con el objetivo de describir las características y comportamientos de este conjunto mediante las siguientes medidas resumen: número total de observaciones (count), media (mean), desviación estándar (std), valor mínimo (min), valor máximo (max) y los valores de los diferentes cuartiles (25%, 50%, 75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos estadísticos de cada uno de los atributos\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Visualizar los datos**\n",
    "\n",
    "Una manera visual de entender los datos de entrada. \n",
    "1. Histograma\n",
    "2. Curva de densidad\n",
    "3. Boxplots\n",
    "4. Matriz de correlación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Histograma**\n",
    "\n",
    "Respresentación gráfica de cada uno de los atributos en forma de barras, donde la superficie de la barra es proporcional a la frecuencia de los valores representados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma = dataset.hist(xlabelsize=10, ylabelsize=10, bins=100, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Gráfico de densidades**\n",
    "\n",
    "Visualiza la distribución de los datos. Es una variable del histograma, pero elimina el ruido, por lo que son mejores para determinar la forma de distribución de un atributo. Lo spicos del gráfico de densidad ayudan a mostrar dónde los valores se concentran más. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = dataset.plot(kind='kde', x=4, subplots=True, legend=True, layout=(4, 3), figsize=(10, 10), sharex=False,\n",
    "                        fontsize=8, stacked=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Boxplots** \n",
    "\n",
    "El boxplot (diagrama de caja) nos permite identificar los valores atípicos y comparar distribuciones. Además, se conoce como se distribuyen el 50% de los valores (dentro de la caja). \n",
    "\n",
    "En este caso, los outliers aportan bastante información, como por ejemplo un dia sin viento, que provoca un aumento considerable de la energía térmica de carbón. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset.plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11), sharex=False,\n",
    "                                 sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo ha cambiado la distribución de las fuentes de generación en el último año?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_boxplot = dataset[12910:].plot(kind='box', subplots=True, layout=(4, 3), figsize=(11, 11), sharex=False,\n",
    "                                 sharey=False, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Matriz de correlación** \n",
    "\n",
    "Tabla de doble entrada de los atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cálculo de coeficientes de correlación\n",
    "corr_matrix = dataset.corr(method='pearson') \n",
    "\n",
    "# Matriz de correlación\n",
    "fig = plt.figure(figsize=(11, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr_matrix, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, 10, 1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(corr_matrix.columns)\n",
    "ax.set_yticklabels(corr_matrix.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4. Preparar los datos*\n",
    "\n",
    "1. Limpieza de datos (data cleaning)\n",
    "2. Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, divido los datos en **atributos**: X (features) y **etiquetas**: y (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos X (features); etiquetas y (target)\n",
    "X = dataset.drop(['Clases'], axis=1) \n",
    "y = dataset['Clases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Limpieza de datos (data cleaning)**\n",
    "\n",
    "No exisiten Nan en los datos de entrada y no se eliminarán los outliers en este ejemplo. Esto se tratará en la práctica. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Transformación**. \n",
    "\n",
    "Se escalan los datos utilizando el método de *MinMaxScaler()*, que escala y traduce cada atributo individualmente de tal manera que está dentro del rango [0,1]. Esto es necesario hacerlo cuando las escalas de los atributos son diferentes (eg. mes [0, 11], eólica [515.5, 18996.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = X.copy()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(df_scaled))\n",
    "X_scaled.columns = df_scaled.columns\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5. Dividir los datos*\n",
    "\n",
    "Se utiliza la semilla ***randome_state=0*** para todos los ejercicios. ***Suffle=True*** indica que los datos se reparten de forma aleatoria entre entreno y prueba. Esto reduce la varianza y evita que el modelo no cree un sobreajuste (overfitting). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # porcentaje de los datos de entrada que utilizaré para validar el modelo\n",
    "\n",
    "# Divido los datos en datos de entreno, validación y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=0,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6. Construcción y evaluación de modelos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La métrica de evaluacion seleccionada es **balanced_accuracy**. En los problemas de clasificación binaria sirve para evaluar a los conjuntos de datos desequilibrados. Se define como el promedio de **Recall** obtenido de cada clase.\n",
    "* Se evaluan los siguientes algoritmos: \n",
    "    * **Logistic Regression** *LogisticRegression()*\n",
    "    * **Support Vector Machine** Classifier *SVC()*\n",
    "    * **K-nearest neighbors Classifier** *KNeighborsClassifier()*\n",
    "    * **Decision Tree Classifier** *DecisionTreeClassifier()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_folds = 5\n",
    "error_metrics = {'balanced_accuracy'}\n",
    "models = {('LR', LogisticRegression()), ('SVC', SVC()), ('KNN', KNeighborsClassifier()),\n",
    "           ('DTC', DecisionTreeClassifier())}\n",
    "\n",
    "results = [] # guarda los resultados de las métricas de evaluación\n",
    "names = []  # Nombre de cada algoritmo\n",
    "msg = []  # imprime el resumen del método de cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenan cada uno de los modelos, se guarda su resultado y se comparan gráficamente. El que mejor resultado da es el **KNN**, ya que su balanced_accuracy es la más alta y su desviación típica es menor (más preciso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Entreno con validación cruzada\n",
    "for scoring in error_metrics:\n",
    "    print('Métrica de evaluación: ', scoring)\n",
    "    for name, model in models:\n",
    "        print('Modelo ', name)\n",
    "        cross_validation = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cross_validation, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        resume = (name, cv_results.mean(), cv_results.std())\n",
    "        msg.append(resume)\n",
    "    print(msg)\n",
    "\n",
    "    # Comparar resultados entre algoritmos\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparación de algoritmos con métrica de evaluación: %s' %scoring)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('Modelos candidatos')\n",
    "    ax.set_ylabel('%s' %scoring)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7. Ajustar hiperparámetros*\n",
    "\n",
    "Pasos para realizar el hiperajuste de los parámetros:\n",
    "* Especificar el modelo a ajustar: *KNeighborsClassifier()*\n",
    "* Especificar una métrica para optimizar: *balanced_accuracy*\n",
    "* Definir los rangos de los parámetros de búsqueda: *params*\n",
    "* Asignar un método de validación: *KFold*\n",
    "* Entrenar con los datos de validación: *X_val*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor\n",
    "\n",
    "modelo = KNeighborsClassifier()\n",
    "scoring='balanced_accuracy'\n",
    "params = {\n",
    "     'n_neighbors': [5, 20, 50], #default=5\n",
    "     'weights': ['uniform','distance'], #'uniform','distance'\n",
    "     'leaf_size': [30,40], #default=30\n",
    "     'p': [2,6], #default=2\n",
    " }\n",
    "\n",
    "# Búsqueda de la mejor combinación de hiperparámetros\n",
    "cross_validation = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "my_cv = cross_validation.split(X_val)\n",
    "gsearch = GridSearchCV(estimator=modelo, param_grid=params, scoring=scoring, cv=my_cv)\n",
    "gsearch.fit(X_val, y_val)\n",
    "\n",
    "# Imprimo el mejor resultado\n",
    "print(\"Mejor resultado: %f utilizando los siguientes hiperparámetros %s\" % (gsearch.best_score_, gsearch.best_params_))\n",
    "means = gsearch.cv_results_['mean_test_score']\n",
    "stds = gsearch.cv_results_['std_test_score']\n",
    "params = gsearch.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *8. Evaluación final del modelo*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de evaluación:\n",
    "  * 1. Matriz de confusión\n",
    "  * 2. Coeficiente de Matthews (MCC)\n",
    "\n",
    "    \n",
    "Finalmente, entreno al modelo con los hiperparámetros óptimos encontrados en el apartado anterior y realizo las predicciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_final = KNeighborsClassifier(n_neighbors=5, weights='distance', leaf_size=30, p=2)\n",
    "modelo_final.fit(X_train,y_train)  # Se entrena al modelo KNN\n",
    "y_predict = modelo_final.predict(X_test)  # Se calculan las predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico no normalizado de la martiz de confusión\n",
    "disp = plot_confusion_matrix(modelo_final, X_test, y_test,\n",
    "                                 cmap=plt.cm.YlGn, values_format = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Coeficiente de Matthews (MCC)**\n",
    "\n",
    "El MCC utiliza coeficientes de correlación entre -1 y +1. \n",
    "* Coeficiente +1 representa una predicción perfecta\n",
    "* Coeficiente 0 representa una predicción media aleatoria\n",
    "* Coeficiente -1 representa una predicción inversa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_corrcoef(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones  \n",
    "\n",
    "* El modelo KNN tiene bastante acierto, incluso en la clase minoritaria (precios de la electricidad elevados = 1).\n",
    "* El atributo que más influye en la predicción es la generación de carbón. \n",
    "* Se pueden realizar mejoras, como por ejemplo feature selection (elegir atributos con mayor peso en la clasificación), entrenar con otros algoritmos (Random Forest), comprobar si los resultados dan mejor entrenando diferentes modelos para las diferentes estaciones del año, entrenar al modelo con StratifiesShuffle, etc. \n",
    "* MCC es 0.91, lo cual indica una predicción altamente exacta y precisa. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
